# üê±üê∂üêæ Classificador de Ra√ßas de C√£es e Gatos

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

Projeto de Aprendizado de M√°quina com foco na classifica√ß√£o multiclasse de ra√ßas de animais de estima√ß√£o. O modelo √© capaz de identificar a ra√ßa presente em uma imagem dentre as seguintes op√ß√µes: Pomeranian, Egyptian Mau, Ragdoll e Shiba Inu.

## Tabela de Conte√∫dos
- [Vis√£o Geral](#-vis√£o-geral)
- [Objetivos](#-objetivos)
- [Estrutura do Reposit√≥rio](#-estrutura-do-reposit√≥rio)
- [Metodologia](#-metodologia)
- [Tecnologias Utilizadas](#Ô∏è-tecnologias-utilizadas)
- [Como Executar o Projeto](#-como-executar-o-projeto)
- [Resultados](#-resultados)
- [Autor](#Ô∏è-autor)

## üî≠ Vis√£o Geral

Este projeto explora a constru√ß√£o de um pipeline de Machine Learning para um problema de classifica√ß√£o de imagens. Partindo de um subconjunto do famoso *Oxford-IIIT Pet Dataset*, o desafio √© treinar e avaliar diferentes modelos para distinguir entre quatro ra√ßas espec√≠ficas, sendo duas de c√£es e duas de gatos:

* üêï **Pomeranian**
* üêà **Egyptian Mau**
* üêà **Ragdoll**
* üêï **Shiba Inu**

O desenvolvimento foi dividido em checkpoints, permitindo uma an√°lise incremental do desempenho √† medida que diferentes t√©cnicas e modelos eram introduzidos, culminando em uma verifica√ß√£o estat√≠stica da relev√¢ncia dos resultados.

## üìå Objetivos

* Treinar modelos capazes de classificar imagens nas 4 ra√ßas distintas.
* Explorar e comparar diferentes extratores de caracter√≠sticas de imagens: **HOG** (cl√°ssico) e **CNNs** (baseado em Deep Learning).
* Avaliar e comparar o desempenho de modelos cl√°ssicos de Machine Learning, Redes Neurais e Comit√™s de Classificadores.
* Analisar o impacto da redu√ß√£o de dimensionalidade com **PCA** na performance dos modelos.
* Validar estatisticamente os resultados dos modelos com os testes de **Friedman** e **Nemenyi**.

## üìÇ Estrutura do Reposit√≥rio

O projeto est√° organizado da seguinte forma para garantir clareza e reprodutibilidade:

```
/
‚îú‚îÄ‚îÄ data/               # Armazena os dados brutos e processados
‚îú‚îÄ‚îÄ notebooks/          # Notebooks Jupyter com o passo a passo das an√°lises
‚îú‚îÄ‚îÄ reports/            # Relat√≥rios, gr√°ficos e matrizes de confus√£o
‚îú‚îÄ‚îÄ src/                # C√≥digo fonte com fun√ß√µes reutiliz√°veis
‚îú‚îÄ‚îÄ README.md           # Este arquivo
‚îî‚îÄ‚îÄ requirements.txt    # Depend√™ncias do projeto
```

## üî¨ Metodologia

#### 1. Base de Dados
Utilizou-se um subconjunto da base p√∫blica **Oxford-IIIT Pet Dataset**.
* **Fonte oficial:** [VGG - Oxford Pet Dataset](https://www.robots.ox.ac.uk/~vgg/data/pets/)
* **Ra√ßas selecionadas:** Pomeranian, Egyptian Mau, Ragdoll e Shiba Inu.

#### 2. Extra√ß√£o de Caracter√≠sticas
Para que os modelos pudessem "entender" as imagens, elas foram convertidas em vetores num√©ricos usando duas abordagens:
* **HOG (Histogram of Oriented Gradients):** Um extrator de caracter√≠sticas cl√°ssico que captura informa√ß√µes sobre formas e contornos.
* **CNNs Pr√©-treinadas (VGG16 e VGG19):** Utilizou-se o poder de redes neurais convolucionais j√° treinadas em um vasto dataset (ImageNet) para extrair caracter√≠sticas complexas e de alto n√≠vel das imagens.

#### 3. Redu√ß√£o de Dimensionalidade
* **PCA (An√°lise de Componentes Principais):** Aplicado sobre os vetores de caracter√≠sticas para reduzir sua dimensionalidade, otimizando o tempo de treinamento e, em alguns casos, melhorando a performance dos modelos.

#### 4. Modelagem e Valida√ß√£o
O treinamento foi dividido em etapas sequenciais, com cada notebook focando em uma parte do processo:
* **Checkpoint 1: `k-NN e PCA`**
    * Treinamento do modelo **k-NN** com as diferentes bases de caracter√≠sticas (HOG, VGG16, VGG19).
    * Avalia√ß√£o do impacto do PCA nas seis melhores bases geradas pelas CNNs.
* **Checkpoint 2: `Naive Bayes e Decision Tree`**
    * Treinamento e an√°lise dos modelos **Naive Bayes** e **√Årvore de Decis√£o**.
* **Checkpoint 3: `Redes Neurais - MLP`**
    * Implementa√ß√£o e avalia√ß√£o de uma rede neural **Multilayer Perceptron (MLP)**.
* **Checkpoint 4: `Comit√™s de Classificadores`**
    * Explora√ß√£o de m√©todos de conjunto (*ensemble methods*): **Bagging, Boosting, Stacking, Random Forest** e **XGBoost**.
* **Checkpoint 5: `Testes Estat√≠sticos`**
    * Aplica√ß√£o dos testes de **Friedman** e **Nemenyi** para comparar estatisticamente o desempenho dos algoritmos e validar se as diferen√ßas de performance s√£o significativas.

## üõ†Ô∏è Tecnologias Utilizadas

* **Python 3.x**
* **TensorFlow & Keras:** Para extra√ß√£o de caracter√≠sticas com CNNs e modelagem com Redes Neurais.
* **Scikit-Learn:** Para modelos de ML, pr√©-processamento (PCA) e m√©tricas de avalia√ß√£o.
* **NumPy & Pandas:** Para manipula√ß√£o de dados e vetores.
* **Matplotlib & Seaborn:** Para visualiza√ß√£o de dados e resultados.
* **Jupyter Notebook:** Para experimenta√ß√£o e an√°lise interativa.

## üöÄ Como Executar o Projeto

1.  **Clone o reposit√≥rio:**
    ```bash
    git clone [https://github.com/luiz-pytech/Classificador_Racas_gato_Cachorro.git](https://github.com/luiz-pytech/Classificador_Racas_gato_Cachorro.git)
    cd Classificador_Racas_gato_Cachorro
    ```

2.  **Crie e ative um ambiente virtual (recomendado):**
    ```bash
    python -m venv venv
    # No Windows
    .\venv\Scripts\activate
    # No macOS/Linux
    source venv/bin/activate
    ```

3.  **Instale as depend√™ncias:**
    ```bash
    pip install -r requirements.txt
    ```
    *Dica: Para gerar o `requirements.txt` atualizado, use o comando `pip freeze > requirements.txt`.*

4.  **Execute os notebooks:**
    Abra os notebooks na pasta `/notebooks`. Recomenda-se seguir a ordem definida pelos checkpoints para um entendimento completo do fluxo de trabalho.

## üìä Resultados

Os resultados detalhados, incluindo m√©tricas de acur√°cia, matrizes de confus√£o e os testes estat√≠sticos, podem ser encontrados nos notebooks e nos arquivos da pasta [`/reports/`](./reports/) e figuras em [`/reports/figures`](./reports/figures) .

**Principais Conclus√µes:**

* **Extra√ß√£o de Caracter√≠sticas:** A abordagem com **CNNs pr√©-treinadas (VGG16/VGG19)** apresentou um desempenho significativamente superior ao **HOG**. O HOG demonstrou limita√ß√µes para abstrair caracter√≠sticas robustas a varia√ß√µes de √¢ngulo, ilumina√ß√£o e pose dos animais.

* **Desempenho dos Modelos:** Dentre os modelos individuais, a rede neural **MLP (Multilayer Perceptron)** alcan√ßou a maior acur√°cia. Entre os comit√™s, o modelo de **Stacking** com 5 classificadores se destacou como a abordagem mais perform√°tica.

* **Impacto do PCA:** A aplica√ß√£o do PCA mostrou-se muito eficaz. Al√©m de reduzir drasticamente a dimensionalidade dos dados (otimizando o custo computacional), a t√©cnica tamb√©m levou a um aumento na acur√°cia da maioria dos modelos testados.

## üìä Resultados Quantitativos

Abaixo est√£o as tabelas com as m√©tricas de acur√°cia para cada modelo e extrator de caracter√≠sticas.

### Tabela 1: Acur√°cia por Modelo e Extrator de Caracter√≠sticas

| Modelo | Extrator HOG | Extrator VGG16 | Extrator VGG19 |
| :--- | :---: | :---: | :---: |
| **k-NN** | 32,86% | 95,67% | 95,67% |
| **√Årvore de Decis√£o** | 30,21% | 91,14% | 85,73% |
| **Naive Bayes** | 45,71% | 96,56% | 96,14% |
| **MLP (Rede Neural)**| XX | 99,16 | 99,16% |

### Tabela 2: Acur√°cia dos Comit√™s de Classificadores (Ensembles)

| Comit√™ | Acur√°cia |
| :--- | :---: |
| **Random Forest** | 97,15% |
| **Bagging** | 95,97% |
| **Boosting** |92,83% |
| **Stacking** | 98% |

---

## ‚úçÔ∏è Autor

* **Luiz Felipe de Souza Silva**
